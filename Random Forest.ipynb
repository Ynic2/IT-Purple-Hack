{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c1c026e",
   "metadata": {},
   "source": [
    "# Предобработка данных для обучения Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d7ad41",
   "metadata": {},
   "source": [
    "### Загрузка данных и первоначальная обработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcfef39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "from collections import Counter\n",
    "\n",
    "print(\"Шаг 1: Загрузка данных...\")\n",
    "df_train = pq.read_table(\"train_ai_comp_final_dp.parquet\").to_pandas()\n",
    "\n",
    "# Подготовка данных\n",
    "print(\"Шаг 2: Подготовка данных...\")\n",
    "X = df_train.drop([\"sample_ml_new\", \"feature642\", \"feature756\", \"target\"], axis=1)\n",
    "y = df_train[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b0a685",
   "metadata": {},
   "source": [
    "### Сэмплирование данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1267977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Применение SMOTE для сэмплирования данных\n",
    "print(\"Шаг 3: Применение сэмплирования...\")\n",
    "# Подсчет количества примеров в каждом классе\n",
    "print(\"До сэмплирования:\", Counter(y))\n",
    "\n",
    "\n",
    "# Создание пайплайна с oversampling и undersampling\n",
    "pipeline = Pipeline([\n",
    "    #('oversample', SMOTE(sampling_strategy=1)),  # Увеличение примеров класса меньшинства до 50% от размера класса большинства\n",
    "    ('undersample', RandomUnderSampler(sampling_strategy=1.0))  # Уменьшение примеров класса большинства до размера класса меньшинства\n",
    "])\n",
    "X_resampled, y_resampled = pipeline.fit_resample(X, y)\n",
    "\n",
    "print(\"После сэмплирования: \", Counter(y_resampled))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb56790d",
   "metadata": {},
   "source": [
    "### Выявление наиболее значимых признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ded17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "print(\"Шаг 4: Выявление наиболее значимых признаков...\")\n",
    "rf_model = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "rf_model.fit(X_resampled, y_resampled)\n",
    "feature_importances = rf_model.feature_importances_\n",
    "important_features_indices = feature_importances.argsort()[-100:][::-1]  # Выбираем 100 наиболее значимых признаков\n",
    "\n",
    "# Использование только наиболее значимых признаков\n",
    "X_important = X_resampled.iloc[:, important_features_indices]\n",
    "print(important_features_indices)\n",
    "\n",
    "# Разделение данных на обучающий и валидационный наборы\n",
    "print(\"Шаг 5: Разделение данных на обучающий и валидационный наборы...\")\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_important, y_resampled, test_size=0.25, random_state=42)\n",
    "\n",
    "# Сохранение модели\n",
    "print(\"Шаг 6: Сохранение модели...\")\n",
    "joblib.dump(rf_model, 'random_forest_model.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbe9442",
   "metadata": {},
   "source": [
    "### Обучение модели Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de71225f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализация и обучение модели Random Forest\n",
    "print(\"Шаг 7: Инициализация и обучение модели Random Forest...\")\n",
    "rf_model = RandomForestClassifier(n_estimators=300, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Предсказание на валидационном наборе\n",
    "print(\"Шаг 8: Предсказание на валидационном наборе...\")\n",
    "y_pred = rf_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a074817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вычисление метрик\n",
    "print(\"Шаг 9: Вычисление метрик...\")\n",
    "precision = precision_score(y_val, y_pred)\n",
    "recall = recall_score(y_val, y_pred)\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "roc_auc = roc_auc_score(y_val, y_pred)\n",
    "\n",
    "# Сохранение модели\n",
    "print(\"Шаг 10: Сохранение новой модели...\")\n",
    "joblib.dump(rf_model, 'random_forest_model_after.model')\n",
    "\n",
    "# Вывод результатов\n",
    "print(\"Метрики:\")\n",
    "print(f\"  Precision: {precision}\")\n",
    "print(f\"  Recall: {recall}\")\n",
    "print(f\"  F1 Score: {f1}\")\n",
    "print(f\"  ROC AUC Score: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e86351e",
   "metadata": {},
   "source": [
    "# Проверка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cbb7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pickle\n",
    "\n",
    "# Загрузка модели\n",
    "loaded_model = joblib.load('random_forest_model_after.model')\n",
    "print(type(loaded_model))\n",
    "# Загрузка тестовых данных\n",
    "file_path = \"test_sber.parquet\"\n",
    "file_name, file_extension = os.path.splitext(file_path)\n",
    "\n",
    "needToDelete = [\"feature642\", \"feature756\", \"sample_ml_new\"]\n",
    "\n",
    "df = pq.read_table(file_path).to_pandas()\n",
    "\n",
    "df = df.drop(needToDelete, axis=1)\n",
    "\n",
    "#feature_indices = [1, 4, 43, 67, 88, 89, 90, 91, 93, 96, 98, 119, 124, 129, 130, 137, 195, 262, 263, 270, 282, 283, 284, 286, 287, 288, 309, 313, 342, 349, 350, 357, 358, 359, 385, 395, 396, 402, 432, 434, 437, 438, 440, 441, 445, 461, 464, 467, 472, 479, 481, 482, 485, 489, 529, 548, 614, 667, 674, 675, 692, 720, 726, 738, 741, 744, 745, 752, 753, 780, 791, 797, 808, 810, 813, 852, 859, 862, 863, 852, 859, 862, 863, 852, 859, 862, 863, 852, 859, 862, 863, 852, 859, 862, 863, 852, 859, 862, 863, 852, 859, 862, 863, 852, 859, 862, 863, 986, 992, 996, 998, 1000, 1003, 1004, 1074, 1076, 116, 341, 443, 444, ]\n",
    "feature_names = loaded_model.feature_names_in_\n",
    "#feature_names = np.append(feature_names, \"id\")\n",
    "\n",
    "print(\"Идет удаление ненужных признаков...\")\n",
    "df_test = df[feature_names]\n",
    "print(\"Удаление завершено\\n\")\n",
    "\n",
    "X_test = df\n",
    "\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "\n",
    "# Предсказание\n",
    "predictions = loaded_model.predict_proba(df_test)[:, 1]\n",
    "\n",
    "rounded_predictions = [round(pred) for pred in predictions]\n",
    "\n",
    "count_of_1 = sum(predictions)\n",
    "print(\"Количество 1: \", count_of_1)\n",
    "print(\"Количество всего: \", len(predictions))\n",
    "\n",
    "# Создание DataFrame с предсказаниями и id\n",
    "df_predictions = pd.DataFrame({'id': df['id'],'target_bin': rounded_predictions, 'target_prob': predictions})\n",
    "\n",
    "# Сохранение предсказаний в CSV файл\n",
    "df_predictions.to_csv('test.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cf5acb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
