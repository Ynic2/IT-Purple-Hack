{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "015aa062",
   "metadata": {},
   "source": [
    "# Предобработка данных для обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2d3822",
   "metadata": {},
   "source": [
    "### Загрузка данных и первоначальная обработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdd3dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import layers, models, initializers, callbacks\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "def amountOfNone(df, text):\n",
    "    rows_with_missing_values = df.isna().any(axis=1)\n",
    "    count_rows_with_missing_values = rows_with_missing_values.sum()\n",
    "    print(f\"{text}: {count_rows_with_missing_values}\")\n",
    "\n",
    "print(\"Идет удаление...\")\n",
    "df = pq.read_table(\"train_ai_comp_final_dp.parquet\").to_pandas()\n",
    "df.drop(['id','sample_ml_new', 'feature642', 'feature756'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84211309",
   "metadata": {},
   "source": [
    "### Нормализация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a23a089",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Нормализация...\")\n",
    "numeric_columns = df.select_dtypes(include=['number']).columns.drop('target')\n",
    "# Создаем экземпляр класса MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "# Применяем MinMaxScaler к выбранным числовым столбцам\n",
    "df[numeric_columns] = scaler.fit_transform(df[numeric_columns])\n",
    "\n",
    "X = df.drop(['target'], axis=1)\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ba2450",
   "metadata": {},
   "source": [
    "### Сэмплирование данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3beb89fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем пайплайн для ADASYN и RandomUnderSampler\n",
    "pipeline = Pipeline([\n",
    "    ('adasyn', ADASYN(sampling_strategy={1: 30000}, n_neighbors=5, random_state=42)),\n",
    "    ('under', RandomUnderSampler(sampling_strategy={0: 30000}, random_state=42))\n",
    "])\n",
    "\n",
    "X_resampled, y_resampled = pipeline.fit_resample(X, y)\n",
    "\n",
    "df_resampled = pd.concat([pd.DataFrame(y_resampled), pd.DataFrame(X_resampled, columns=X.columns)], axis=1)\n",
    "df_resampled.drop_duplicates(inplace=True)\n",
    "print(f\"После ресемплинга количество экземпляров 'target=1': {(df_resampled['target'] == 1).sum()}\")\n",
    "print(f\"После ресемплинга количество экземпляров 'target=0': {(df_resampled['target'] == 0).sum()}\")\n",
    "\n",
    "amountOfNone(df_resampled, \"Количество строк с пропущенными значениями после ресемплинга\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50147e8",
   "metadata": {},
   "source": [
    "# Обучение модели логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b323940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предположим, что target_column - это название вашей целевой колонки, а остальные колонки - это признаки\n",
    "X = df_resampled.drop('target', axis=1)\n",
    "y = df_resampled['target']\n",
    "\n",
    "# Разделение данных\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Создание и обучение модели\n",
    "logistic_model = LogisticRegression(penalty=\"l2\",solver='saga',class_weight='balanced',tol=1e-7,max_iter=10000, random_state=42)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Прогнозирование вероятностей для обучающего и тестового наборов\n",
    "y_train_pred = logistic_model.predict_proba(X_train)[:, 1]\n",
    "y_test_pred = logistic_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Расчет метрик\n",
    "train_logloss = log_loss(y_train, y_train_pred)\n",
    "train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "test_logloss = log_loss(y_test, y_test_pred)\n",
    "test_auc = roc_auc_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Train Logloss: {train_logloss}, Train AUC: {train_auc}\")\n",
    "print(f\"Test Logloss: {test_logloss}, Test AUC: {test_auc}\")\n",
    "\n",
    "# Сохранение модели\n",
    "joblib.dump(logistic_model, 'logistic_regression_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f448078a",
   "metadata": {},
   "source": [
    "### Проверка модели логической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524085f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_model(path_to_model):\n",
    "    # Загрузка модели из файла\n",
    "    return joblib.load(path_to_model)\n",
    "\n",
    "def predict(model, data):\n",
    "    # Получение предсказаний от модели\n",
    "    predictions = model.predict_proba(data)[:, 1]\n",
    "    return predictions\n",
    "\n",
    "def load_data(path_to_data):\n",
    "    # Загрузка данных\n",
    "    df = pq.read_table(path_to_data).to_pandas()\n",
    "    features = ['sample_ml_new','feature756','feature642',]\n",
    "\n",
    "    # Предположим, что 'target' - это название вашей целевой колонки, которую мы удаляем для предсказания\n",
    "    X = df.drop(features,axis=1)\n",
    "\n",
    "    numeric_columns = X.select_dtypes(include=['number']).columns.drop('id')\n",
    "    # Создаем экземпляр класса MinMaxScaler\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    # Применяем MinMaxScaler к выбранным числовым столбцам\n",
    "    X[numeric_columns] = scaler.fit_transform(X[numeric_columns])\n",
    "\n",
    "    return X\n",
    "\n",
    "path_to_model = 'logistic_regression_model.pkl'\n",
    "path_to_data = 'test_sber.parquet'\n",
    "\n",
    "# Загрузка модели\n",
    "model = load_model(path_to_model)\n",
    "\n",
    "# Загрузка данных\n",
    "data = load_data(path_to_data)\n",
    "data2 = data.drop('id',axis=1)\n",
    "# Получение и вывод предсказаний\n",
    "predictions = predict(model,data2)\n",
    "prediction_rounded = np.round(predictions).astype(int)\n",
    "df1 = pd.DataFrame({\n",
    "    \"id\": data['id'],\n",
    "    \"target_bin\": prediction_rounded,\n",
    "    \"target_prob\": predictions\n",
    "})\n",
    "\n",
    "df1.to_csv('predicions_test_logic.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8376b2ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
