{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "015aa062",
   "metadata": {},
   "source": [
    "# Предобработка данных для обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2d3822",
   "metadata": {},
   "source": [
    "### Загрузка данных и первоначальная обработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcdd3dc7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers, models, initializers, callbacks\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m precision_score, recall_score, f1_score\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import layers, models, initializers, callbacks\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "def amountOfNone(df, text):\n",
    "    rows_with_missing_values = df.isna().any(axis=1)\n",
    "    count_rows_with_missing_values = rows_with_missing_values.sum()\n",
    "    print(f\"{text}: {count_rows_with_missing_values}\")\n",
    "\n",
    "print(\"Идет удаление...\")\n",
    "df = pq.read_table(\"train_ai_comp_final_dp.parquet\").to_pandas()\n",
    "df.drop(['id','sample_ml_new', 'feature642', 'feature756'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84211309",
   "metadata": {},
   "source": [
    "### Нормализация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a23a089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Нормализация...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mНормализация...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m numeric_columns \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumber\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Создаем экземпляр класса MinMaxScaler\u001b[39;00m\n\u001b[0;32m      4\u001b[0m scaler \u001b[38;5;241m=\u001b[39m MinMaxScaler(feature_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Нормализация...\")\n",
    "numeric_columns = df.select_dtypes(include=['number']).columns.drop('target')\n",
    "# Создаем экземпляр класса MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "# Применяем MinMaxScaler к выбранным числовым столбцам\n",
    "df[numeric_columns] = scaler.fit_transform(df[numeric_columns])\n",
    "\n",
    "X = df.drop(['target'], axis=1)\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ba2450",
   "metadata": {},
   "source": [
    "### Сэмплирование данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3beb89fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем пайплайн для ADASYN и RandomUnderSampler\n",
    "pipeline = Pipeline([\n",
    "    ('adasyn', ADASYN(sampling_strategy={1: 30000}, n_neighbors=5, random_state=42)),\n",
    "    ('under', RandomUnderSampler(sampling_strategy={0: 30000}, random_state=42))\n",
    "])\n",
    "\n",
    "X_resampled, y_resampled = pipeline.fit_resample(X, y)\n",
    "\n",
    "df_resampled = pd.concat([pd.DataFrame(y_resampled), pd.DataFrame(X_resampled, columns=X.columns)], axis=1)\n",
    "df_resampled.drop_duplicates(inplace=True)\n",
    "print(f\"После ресемплинга количество экземпляров 'target=1': {(df_resampled['target'] == 1).sum()}\")\n",
    "print(f\"После ресемплинга количество экземпляров 'target=0': {(df_resampled['target'] == 0).sum()}\")\n",
    "\n",
    "amountOfNone(df_resampled, \"Количество строк с пропущенными значениями после ресемплинга\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50147e8",
   "metadata": {},
   "source": [
    "# Обучение модели логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b323940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предположим, что target_column - это название вашей целевой колонки, а остальные колонки - это признаки\n",
    "X = df_resampled.drop('target', axis=1)\n",
    "y = df_resampled['target']\n",
    "\n",
    "# Разделение данных\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Создание и обучение модели\n",
    "logistic_model = LogisticRegression(penalty=\"l2\",solver='saga',class_weight='balanced',tol=1e-7,max_iter=10000, random_state=42)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Прогнозирование вероятностей для обучающего и тестового наборов\n",
    "y_train_pred = logistic_model.predict_proba(X_train)[:, 1]\n",
    "y_test_pred = logistic_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Расчет метрик\n",
    "train_logloss = log_loss(y_train, y_train_pred)\n",
    "train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "test_logloss = log_loss(y_test, y_test_pred)\n",
    "test_auc = roc_auc_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Train Logloss: {train_logloss}, Train AUC: {train_auc}\")\n",
    "print(f\"Test Logloss: {test_logloss}, Test AUC: {test_auc}\")\n",
    "\n",
    "# Сохранение модели\n",
    "joblib.dump(logistic_model, 'logistic_regression_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f448078a",
   "metadata": {},
   "source": [
    "### Проверка модели логической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "524085f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ynicp\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 1.4.1.post1 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def load_model(path_to_model):\n",
    "    # Загрузка модели из файла\n",
    "    return joblib.load(path_to_model)\n",
    "\n",
    "def predict(model, data):\n",
    "    # Получение предсказаний от модели\n",
    "    predictions = model.predict_proba(data)[:, 1]\n",
    "    return predictions\n",
    "\n",
    "def load_data(path_to_data):\n",
    "    # Загрузка данных\n",
    "    df = pq.read_table(path_to_data).to_pandas()\n",
    "    features = ['sample_ml_new','feature756','feature642',]\n",
    "\n",
    "    # Предположим, что 'target' - это название вашей целевой колонки, которую мы удаляем для предсказания\n",
    "    X = df.drop(features,axis=1)\n",
    "\n",
    "    numeric_columns = X.select_dtypes(include=['number']).columns.drop('id')\n",
    "    # Создаем экземпляр класса MinMaxScaler\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    # Применяем MinMaxScaler к выбранным числовым столбцам\n",
    "    X[numeric_columns] = scaler.fit_transform(X[numeric_columns])\n",
    "\n",
    "    return X\n",
    "\n",
    "path_to_model = 'logistic_regression_model.pkl'\n",
    "path_to_data = 'test_sber.parquet'\n",
    "\n",
    "# Загрузка модели\n",
    "model = load_model(path_to_model)\n",
    "\n",
    "# Загрузка данных\n",
    "data = load_data(path_to_data)\n",
    "data2 = data.drop('id',axis=1)\n",
    "# Получение и вывод предсказаний\n",
    "predictions = predict(model,data2)\n",
    "prediction_rounded = np.round(predictions).astype(int)\n",
    "df1 = pd.DataFrame({\n",
    "    \"id\": data['id'],\n",
    "    \"target_bin\": prediction_rounded,\n",
    "    \"target_prob\": predictions\n",
    "})\n",
    "\n",
    "df1.to_csv('predicions_test_logic.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8376b2ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
